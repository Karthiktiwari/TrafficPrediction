{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df = pd.read_csv('/home/karthiktiwari/Data/Dataset/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Rainfall_last_hour</th>\n",
       "      <th>Snowfall_last_hour</th>\n",
       "      <th>Cloud_Cover</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Weather_Desc</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Traffic_Vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>289.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cloudy skies</td>\n",
       "      <td>Partly cloudy skies</td>\n",
       "      <td>02/10/08 9:00</td>\n",
       "      <td>02/10/08</td>\n",
       "      <td>5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>290.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Cloudy skies</td>\n",
       "      <td>Fragmented clouds</td>\n",
       "      <td>02/10/08 10:00</td>\n",
       "      <td>02/10/08</td>\n",
       "      <td>4525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>290.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Cloudy skies</td>\n",
       "      <td>Full cloud cover</td>\n",
       "      <td>02/10/08 11:00</td>\n",
       "      <td>02/10/08</td>\n",
       "      <td>4772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>290.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Cloudy skies</td>\n",
       "      <td>Full cloud cover</td>\n",
       "      <td>02/10/08 12:00</td>\n",
       "      <td>02/10/08</td>\n",
       "      <td>5031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>292.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Cloudy skies</td>\n",
       "      <td>Fragmented clouds</td>\n",
       "      <td>02/10/08 13:00</td>\n",
       "      <td>02/10/08</td>\n",
       "      <td>4928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Holiday  Temperature  Rainfall_last_hour  Snowfall_last_hour  Cloud_Cover  \\\n",
       "0      NaN       289.28                 0.0                 0.0           40   \n",
       "1      NaN       290.26                 0.0                 0.0           75   \n",
       "2      NaN       290.28                 0.0                 0.0           90   \n",
       "3      NaN       290.33                 0.0                 0.0           90   \n",
       "4      NaN       292.14                 0.0                 0.0           75   \n",
       "\n",
       "        Weather         Weather_Desc       TimeStamp      Date  Traffic_Vol  \n",
       "0  Cloudy skies  Partly cloudy skies   02/10/08 9:00  02/10/08         5555  \n",
       "1  Cloudy skies    Fragmented clouds  02/10/08 10:00  02/10/08         4525  \n",
       "2  Cloudy skies     Full cloud cover  02/10/08 11:00  02/10/08         4772  \n",
       "3  Cloudy skies     Full cloud cover  02/10/08 12:00  02/10/08         5031  \n",
       "4  Cloudy skies    Fragmented clouds  02/10/08 13:00  02/10/08         4928  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7289"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(traffic_df['Traffic_Vol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.0, 1768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of holidays\n",
    "np.sum(traffic_df['Holiday']).item(), len(np.unique(traffic_df['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3632/2267864254.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  traffic_df['Holiday'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "traffic_df['Holiday'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data points grouped by date column\n",
    "# Intent is to use a seq2seq model for prediction using context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3632/1441635868.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  traffic_df['Date'] = pd.to_datetime(traffic_df['Date'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Convert categorical variables to numerical\n",
    "label_encoders = {}\n",
    "for col in ['Weather', 'Weather_Desc']:\n",
    "    encoder = LabelEncoder()\n",
    "    traffic_df[col] = encoder.fit_transform(traffic_df[col])\n",
    "    label_encoders[col] = encoder\n",
    "\n",
    "# Sort the data by date\n",
    "traffic_df['Date'] = pd.to_datetime(traffic_df['Date'])\n",
    "\n",
    "# Include 'Date' column in features\n",
    "X = traffic_df[['Date', 'Holiday', 'Temperature', 'Rainfall_last_hour', 'Snowfall_last_hour', 'Cloud_Cover', 'Weather', 'Weather_Desc']]\n",
    "y = traffic_df['Traffic_Vol']\n",
    "\n",
    "# Prepare data for sequence-to-sequence model\n",
    "X_seq = X.groupby(pd.to_datetime(X['Date']).dt.date).apply(lambda x: x.values)\n",
    "y_seq = y.groupby(pd.to_datetime(X['Date']).dt.date).apply(lambda x: x.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 289.28, 0.0, 0.0, 40, 3, 19], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X.loc[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for date, rows in X_seq.items():\n",
    "    if rows.shape[0]>max_len:\n",
    "        max_len = rows.shape[0]\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TrafficVolumeDataset(Dataset):\n",
    "    def __init__(self, X_seq, y_seq):\n",
    "        self.X_seq = [x[:, 1:] for x in X_seq]\n",
    "        self.y_seq = y_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_seq)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X_seq[index]\n",
    "        y = self.y_seq[index]\n",
    "        return np.float32(X), np.float32(y)\n",
    "        # return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.0000, 252.8000,   0.0000,   0.0000,   2.0000,   2.0000,   3.0000],\n",
      "        [  0.0000, 251.4900,   0.0000,   0.0000,   2.0000,   2.0000,   3.0000],\n",
      "        [  0.0000, 251.6600,   0.0000,   0.0000,   1.0000,   2.0000,   3.0000],\n",
      "        [  0.0000, 251.5400,   0.0000,   0.0000,  76.0000,   3.0000,   9.0000],\n",
      "        [  0.0000, 250.8400,   0.0000,   0.0000,  75.0000,   3.0000,   9.0000],\n",
      "        [  0.0000, 250.1100,   0.0000,   0.0000,  90.0000,   3.0000,  10.0000],\n",
      "        [  0.0000, 250.1400,   0.0000,   0.0000,  40.0000,   3.0000,  19.0000],\n",
      "        [  0.0000, 249.3000,   0.0000,   0.0000,   1.0000,   2.0000,   3.0000],\n",
      "        [  0.0000, 249.5400,   0.0000,   0.0000,   1.0000,   2.0000,   3.0000],\n",
      "        [  0.0000, 251.6200,   0.0000,   0.0000,   2.0000,   2.0000,   3.0000],\n",
      "        [  0.0000, 252.9900,   0.0000,   0.0000,   1.0000,   2.0000,   3.0000],\n",
      "        [  0.0000, 255.9300,   0.0000,   0.0000,   1.0000,   2.0000,   3.0000],\n",
      "        [  0.0000, 256.5800,   0.0000,   0.0000,  21.0000,   3.0000,  20.0000],\n",
      "        [  0.0000, 256.5000,   0.0000,   0.0000,  20.0000,   3.0000,  20.0000],\n",
      "        [  0.0000, 257.9200,   0.0000,   0.0000,  20.0000,   3.0000,  20.0000],\n",
      "        [  0.0000, 258.3100,   0.0000,   0.0000,  40.0000,   3.0000,  19.0000],\n",
      "        [  0.0000, 257.4800,   0.0000,   0.0000,  40.0000,   3.0000,  19.0000],\n",
      "        [  0.0000, 257.9000,   0.0000,   0.0000,  40.0000,   3.0000,  19.0000],\n",
      "        [  0.0000, 256.9900,   0.0000,   0.0000,  75.0000,   3.0000,   9.0000],\n",
      "        [  0.0000, 256.7200,   0.0000,   0.0000,  90.0000,   3.0000,  10.0000],\n",
      "        [  0.0000, 256.2800,   0.0000,   0.0000,  40.0000,   3.0000,  19.0000],\n",
      "        [  0.0000, 256.5400,   0.0000,   0.0000,  75.0000,   3.0000,   9.0000],\n",
      "        [  0.0000, 255.6600,   0.0000,   0.0000,  90.0000,   3.0000,  10.0000],\n",
      "        [  0.0000, 255.9800,   0.0000,   0.0000,  20.0000,   3.0000,  20.0000]]) tensor([ 481.,  322.,  251.,  384.,  744., 2646., 4776., 5709., 5755., 5192.,\n",
      "        4256., 4605., 4777., 4696., 5230., 5735., 6505., 5902., 4362., 3092.,\n",
      "        3001., 3447., 3503., 1258.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3632/1669368327.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y = self.y_seq[index]\n"
     ]
    }
   ],
   "source": [
    "dataset = TrafficVolumeDataset(X_seq, y_seq)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    X, y = zip(*batch)\n",
    "    \n",
    "    # Get the maximum sequence length\n",
    "    max_length = max(len(x) for x in X)\n",
    "    \n",
    "    \n",
    "    # Pad the sequences to the maximum length\n",
    "    X_padded = torch.nn.utils.rnn.pad_sequence([torch.from_numpy(x) for x in X], batch_first=True, padding_value=0)\n",
    "    y_padded = torch.nn.utils.rnn.pad_sequence([torch.from_numpy(y_i) for y_i in y], batch_first=True, padding_value=0)\n",
    "    \n",
    "    # Get the sequence lengths\n",
    "    lengths = torch.tensor([len(x) for x in X])\n",
    "    \n",
    "    return X_padded, y_padded, lengths\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "for x_samp, y_samp, lengths in dataloader:\n",
    "    print(x_samp[0], y_samp[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.0000, 252.8000,   0.0000,  ...,   2.0000,   2.0000,   3.0000],\n",
       "         [  0.0000, 251.4900,   0.0000,  ...,   2.0000,   2.0000,   3.0000],\n",
       "         [  0.0000, 251.6600,   0.0000,  ...,   1.0000,   2.0000,   3.0000],\n",
       "         ...,\n",
       "         [  0.0000, 256.5400,   0.0000,  ...,  75.0000,   3.0000,   9.0000],\n",
       "         [  0.0000, 255.6600,   0.0000,  ...,  90.0000,   3.0000,  10.0000],\n",
       "         [  0.0000, 255.9800,   0.0000,  ...,  20.0000,   3.0000,  20.0000]],\n",
       "\n",
       "        [[  0.0000, 286.8200,   0.0000,  ...,   0.0000,   2.0000,   3.0000],\n",
       "         [  0.0000, 286.2600,   0.0000,  ...,   0.0000,   2.0000,   3.0000],\n",
       "         [  0.0000, 285.8800,   0.0000,  ...,   0.0000,   2.0000,   3.0000],\n",
       "         ...,\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "\n",
       "        [[  0.0000, 272.6100,   0.0000,  ...,  21.0000,   3.0000,  20.0000],\n",
       "         [  0.0000, 272.7000,   0.0000,  ...,  75.0000,   3.0000,   9.0000],\n",
       "         [  0.0000, 271.8000,   0.0000,  ...,  75.0000,   3.0000,   9.0000],\n",
       "         ...,\n",
       "         [  0.0000, 276.4300,   0.0000,  ...,  90.0000,   3.0000,  10.0000],\n",
       "         [  0.0000, 275.9700,   0.0000,  ...,  90.0000,   3.0000,  10.0000],\n",
       "         [  0.0000, 275.8800,   0.0000,  ...,  91.0000,   3.0000,  10.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.0000, 267.1600,   0.0000,  ...,   1.0000,   2.0000,   3.0000],\n",
       "         [  0.0000, 267.4600,   0.0000,  ...,  40.0000,   3.0000,  19.0000],\n",
       "         [  0.0000, 268.5300,   0.0000,  ...,  90.0000,   3.0000,  10.0000],\n",
       "         ...,\n",
       "         [  0.0000, 273.4700,   0.0000,  ...,  40.0000,   3.0000,  19.0000],\n",
       "         [  0.0000, 272.9900,   0.0000,  ...,   1.0000,   2.0000,   3.0000],\n",
       "         [  0.0000, 271.7200,   0.0000,  ...,   1.0000,   2.0000,   3.0000]],\n",
       "\n",
       "        [[  0.0000, 294.2800,   0.0000,  ...,   1.0000,   7.0000,  26.0000],\n",
       "         [  0.0000, 293.9500,   0.0000,  ...,  91.0000,   3.0000,  10.0000],\n",
       "         [  0.0000, 292.8100,   0.0000,  ...,  90.0000,   3.0000,  10.0000],\n",
       "         ...,\n",
       "         [  0.0000, 295.7200,   0.0000,  ...,  90.0000,   9.0000,   1.0000],\n",
       "         [  0.0000, 295.1500,   0.0000,  ...,  75.0000,   3.0000,   9.0000],\n",
       "         [  0.0000, 293.8300,   0.0000,  ...,   2.0000,   6.0000,  16.0000]],\n",
       "\n",
       "        [[  0.0000, 284.0200,   0.0000,  ...,   1.0000,   2.0000,   3.0000],\n",
       "         [  0.0000, 285.1900,   0.0000,  ...,   1.0000,   2.0000,   3.0000],\n",
       "         [  0.0000, 286.8800,   0.0000,  ...,   1.0000,   2.0000,   3.0000],\n",
       "         ...,\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_samp.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3632/2078800113.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  input_size = X_seq[0].shape[1]-1\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]/tmp/ipykernel_3632/1669368327.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y = self.y_seq[index]\n",
      " 13%|█▎        | 2/15 [00:00<00:03,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 3014.1567\n",
      "Epoch [2/15], Loss: 2949.1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [00:01<00:02,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], Loss: 2947.2986\n",
      "Epoch [4/15], Loss: 2973.8999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:01<00:01,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15], Loss: 2989.2842\n",
      "Epoch [6/15], Loss: 3041.9353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [00:01<00:01,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15], Loss: 2986.1921\n",
      "Epoch [8/15], Loss: 2918.8384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [00:01<00:01,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15], Loss: 3070.5332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [00:02<00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], Loss: 2873.4519\n",
      "Epoch [11/15], Loss: 2974.4097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [00:02<00:00,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15], Loss: 2999.6726\n",
      "Epoch [13/15], Loss: 3026.5967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:02<00:00,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15], Loss: 2988.0967\n",
      "Epoch [15/15], Loss: 2965.6160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TrafficVolumeModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_normal_(module.weight)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.LSTM):\n",
    "            for name, param in module.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_normal_(param)\n",
    "                elif 'bias' in name:\n",
    "                    nn.init.constant_(param, 0)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "\n",
    "        # Pass through the LSTM\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "\n",
    "        # Initialize tensor to store predictions\n",
    "        fc_preds = []\n",
    "        \n",
    "        # Process each timestep separately\n",
    "        for timestep in range(output.size(1)):\n",
    "            timestep_pred = self.fc(output[:, timestep, :])\n",
    "            fc_preds.append(timestep_pred)\n",
    "        \n",
    "        # Concatenate all predictions\n",
    "        fc_preds = torch.stack(fc_preds, dim=1)\n",
    "        \n",
    "        return fc_preds.reshape(fc_preds.shape[0], fc_preds.shape[1])\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "input_size = X_seq[0].shape[1]-1\n",
    "hidden_size = 256\n",
    "num_layers = 1\n",
    "output_size = 1\n",
    "\n",
    "# Initialize the model\n",
    "model = TrafficVolumeModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "\n",
    "model.apply(model._init_weights)\n",
    "model.to('cuda')\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "from tqdm import tqdm\n",
    "# Training loop\n",
    "num_epochs = 15\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for inputs, logits, lengths in dataloader:\n",
    "        inputs = inputs.to('cuda')\n",
    "        logits = logits.to('cuda')\n",
    "        # Forward pass\n",
    "        output = model(inputs, lengths)\n",
    "        loss = criterion(output.squeeze(), logits)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 24]), torch.Size([256, 24]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = nn.LSTM(7, 32, 1, batch_first=True)\n",
    "fc1 = nn.Linear(32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import numpy as np\n",
    "\n",
    "# # Flatten the sequence data if required or use time-series aggregation techniques for each sequence\n",
    "# X_flattened = np.array([np.array(X.loc[i][1:], dtype=np.float32) for i in range(len(X))])\n",
    "# y_flattened = np.float32(y)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_flattened, y_flattened, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Define XGBoost model\n",
    "# xgb_model = xgb.XGBRegressor(\n",
    "#     n_estimators=1000,  # Number of boosting rounds\n",
    "#     learning_rate=0.01,  # Step size shrinkage to prevent overfitting\n",
    "#     max_depth=6,  # Maximum depth of a tree\n",
    "#     subsample=0.8,  # Subsample ratio of the training instance\n",
    "#     colsample_bytree=0.8,  # Subsample ratio of columns when constructing each tree\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Train the model\n",
    "# xgb_model.fit(\n",
    "#     X_train, y_train,\n",
    "#     eval_set=[(X_test, y_test)]\n",
    "# )\n",
    "\n",
    "# # Evaluate the model\n",
    "# y_pred = xgb_model.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(f\"Mean Squared Error: {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3632/3375765300.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Holiday'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('/home/karthiktiwari/Data/Dataset/Test.csv')\n",
    "test_df['Holiday'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for col in ['Weather', 'Weather_Desc']:\n",
    "    encoder = LabelEncoder()\n",
    "    test_df[col] = encoder.fit_transform(test_df[col])\n",
    "    label_encoders[col] = encoder\n",
    "test_df['Traffic Vol'] = np.zeros(len(test_df))\n",
    "\n",
    "# Include 'Date' column in features\n",
    "X_test = test_df[['Date', 'Holiday', 'Temperature', 'Rainfall_last_hour', 'Snowfall_last_hour', 'Cloud_Cover', 'Weather', 'Weather_Desc']]\n",
    "y_test = test_df['Traffic_Vol']\n",
    "\n",
    "# Prepare data for sequence-to-sequence model\n",
    "X_test = X_test.groupby(pd.to_datetime(X['Date']).dt.date).apply(lambda x: x.values)\n",
    "y_test = y_test.groupby(pd.to_datetime(X['Date']).dt.date).apply(lambda x: x.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TrafficVolumeDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3632/1669368327.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y = self.y_seq[index]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[  0.  , 297.69,   0.  ,   0.  ,  90.  ,   8.  ,   1.  ],\n",
       "        [  0.  , 296.09,   0.  ,   0.  ,  90.  ,   8.  ,   1.  ],\n",
       "        [  0.  , 294.16,   0.  ,   0.  ,  40.  ,   7.  ,  16.  ],\n",
       "        [  0.  , 292.52,   0.  ,   0.  ,  40.  ,   7.  ,  16.  ],\n",
       "        [  0.  , 291.15,   0.  ,   0.  ,   1.  ,   2.  ,   2.  ],\n",
       "        [  0.  , 289.64,   0.  ,   0.  ,   2.  ,   2.  ,   2.  ],\n",
       "        [  0.  , 289.02,   0.  ,   0.  ,   1.  ,   5.  ,   4.  ],\n",
       "        [  0.  , 288.78,   0.  ,   0.  ,   1.  ,   5.  ,   4.  ],\n",
       "        [  0.  , 288.1 ,   0.  ,   0.  ,   1.  ,   2.  ,   2.  ],\n",
       "        [  0.  , 288.15,   0.  ,   0.  ,   1.  ,   5.  ,   4.  ],\n",
       "        [  0.  , 286.39,   0.  ,   0.  ,   1.  ,   5.  ,   4.  ],\n",
       "        [  0.  , 286.35,   0.  ,   0.  ,   1.  ,   5.  ,   4.  ],\n",
       "        [  0.  , 287.15,   0.  ,   0.  ,  90.  ,   5.  ,   4.  ],\n",
       "        [  0.  , 289.34,   0.  ,   0.  ,   6.  ,   4.  ,   3.  ],\n",
       "        [  0.  , 292.36,   0.  ,   0.  ,   6.  ,   4.  ,   3.  ],\n",
       "        [  0.  , 295.86,   0.  ,   0.  ,   5.  ,   2.  ,   2.  ],\n",
       "        [  0.  , 297.31,   0.  ,   0.  ,   1.  ,   2.  ,   2.  ],\n",
       "        [  0.  , 298.95,   0.  ,   0.  ,   1.  ,   2.  ,   2.  ],\n",
       "        [  0.  , 299.88,   0.  ,   0.  ,  40.  ,   3.  ,  12.  ],\n",
       "        [  0.  , 300.49,   0.  ,   0.  ,  40.  ,   3.  ,  12.  ],\n",
       "        [  0.  , 300.52,   0.  ,   0.  ,  21.  ,   8.  ,   1.  ],\n",
       "        [  0.  , 300.41,   0.  ,   0.  ,  75.  ,   8.  ,  19.  ],\n",
       "        [  0.  , 298.5 ,   0.  ,   0.  ,  76.  ,   7.  ,  11.  ],\n",
       "        [  0.  , 298.09,   0.  ,   0.  ,   1.  ,   2.  ,   2.  ]],\n",
       "       dtype=float32),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3632/1669368327.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y = self.y_seq[index]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Switch the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Create empty lists to store inputs and predictions\n",
    "all_inputs = []\n",
    "all_predictions = []\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=256, shuffle=False, collate_fn=collate_fn, drop_last=False)\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    for inputs, logits, lengths in test_dataloader:\n",
    "        inputs = inputs.to('cuda')\n",
    "        \n",
    "        # Forward pass to get predictions\n",
    "        outputs = model(inputs, lengths)\n",
    "        \n",
    "        # Store the predictions and inputs (moving to CPU if necessary)\n",
    "        all_predictions.append(outputs.flatten().cpu().numpy())\n",
    "        # all_inputs.append(inputs.cpu().numpy())\n",
    "\n",
    "# Concatenate all predictions and inputs\n",
    "# all_inputs = np.concatenate(all_inputs, axis=0)\n",
    "all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "# Create a DataFrame to save results\n",
    "# df_results = pd.DataFrame(all_inputs, columns=[f\"feature_{i}\" for i in range(all_inputs.shape[1])])\n",
    "df_results = pd.DataFrame(all_predictions, columns=['Traffic Vol'])\n",
    "\n",
    "# Save to CSV\n",
    "df_results.to_csv(\"test_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
